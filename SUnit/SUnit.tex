% $Author$
% $Date$
% $Revision$

% HISTORY:
% 2006-12-07 - Stef starts
% 2007-01-26 - Andrew updates
% 2007-05-22 - Andrew first draft
% 2007-06-24 - Oscar edit
% 2009-07-06 - Oscar migrate to pharo
% 2011-06-08 - Mirian traslation finished!.

%=================================================================
\ifx\wholebook\relax\else
% --------------------------------------------
% Lulu:
	\documentclass[a4paper,10pt,twoside]{book}
	\usepackage[
		papersize={6.13in,9.21in},
		hmargin={.75in,.75in},
		vmargin={.75in,1in},
		ignoreheadfoot
	]{geometry}
	\input{../common.tex}
	\pagestyle{headings}
	\setboolean{lulu}{true}
% --------------------------------------------
% A4:
%	\documentclass[a4paper,11pt,twoside]{book}
%	\input{../common.tex}
%	\usepackage{a4wide}
% --------------------------------------------
    \graphicspath{{figures/} {../figures/}}
	\begin{document}
	% \renewcommand{\nnbb}[2]{} % Disable editorial comments
	\sloppy
\fi
%=================================================================
\chapter{SUnit}
\chalabel{SUnit}

%=================================================================
\section{Introducci\'on} 

%\on{Would be nice to have an example of test-driven development with SUnit from beginning to end. Perhaps this is for another chapter?}

\indmain{SUnit} es un peque\~no pero poderoso framework que cuenta con soporte para la creaci\'on y despliegue de pruebas.
Como puede intuirse por su nombre, el dise\`no de \sunit se enfoca en las \emph{Unit Tests} (pruebas unitarias), 
pero tambi\'en puede ser utilizado para pruebas de integraci\'on y pruebas funcionales.
\sunit fue originalmente desarrollado por Kent Beck y posteriormente ampliado por Joseph
Pelrine entre otros, para integrar la noci\'on de un recurso,
el cual describiremos en \secref{resource}.
\index{Beck, Kent}
\index{Pelrine, Joseph}
\seeindex{resource}{test, resource}

El inter\'es en las pruebas y en el \ind{Desarrollo guiado por pruebas -Test Driven Development}
no est\'a limitado a \pharo o a \st.  
Las pruebas automatizadas se han convertido en un sello del movimiento del \ind{desarrollo de software \'Agil (Agile software development)},
y cualquier desarrollador que se ocupe de la mejora de la calidad de software har\'a bien en adoptarlo.
Es m\'as, muchos programadores en diferentes lenguajes han llegado a apreciar el poder
de las pruebas unitarias, y ahora existen versiones de 
\xUnit{}  para muchos lenguajes, tales como \ind{Java}, \ind{Python}, \ind{Perl}, .Net y \ind{Oracle}.

\seeindex{Matrix!free will}{Oracle} % sorry, couldn't resist
%  OSCAR: There was a broken citation here for the xprogramming web site
% I could not figure out what it was supposed to refer to.
Este cap\'itulo describe \SUnit~3.3 (la versi\'on m\'as reciente al momento de editar este texto); el sitio web oficial de \sunit es \url{sunit.sourceforge.net}, donde pueden encontrarse otras actualizaciones.
\index{xUnit}
\index{Net@.Net}

Ni las pruebas, ni la construcci\'on de conjuntos de pruebas, es nuevo:  todos saben que  las pruebas son una buena forma de capturar errores.

La \mbox{\ind{Programaci\'on eXtrema (eXtreme Programming)},} que hace de las pruebas una pr\'actica central
y enfatiza las pruebas automatizadas (\emph{automated} tests), 
ha ayudado a que el desarrollo de pruebas se convierta en algo productivo y entretenido, y no en una tarea m\'as que a los programadores les disguste.

La comunidad \st tiene una larga tradici\'on en la construcci\'on de pruebas porque el estilo de desarrollo incremental est\'a respaldado por su ambiente de desarrollo.
  
En el desarrollo tradicional en \st , el programador escribir\'ia pruebas en un workspace 
tan pronto como un m\'etodo se termina de escribir.
A veces una prueba puede ser incorporada como un comentario en la cabecera
del m\'etodo sobre el cual se est\'a trabajando,
o las pruebas que necesiten alguna configuraci\'on pueden ser inclu\'idas como m\'etodos de ejemplo en la clase.
El problema con estas pr\'acticas es que estas pruebas no est\'an
disponibles para otros programadores que modifiquen el c\'odigo; los comentarios y los m\'etodos de ejemplo son mejores en ese sentido, pero a\'un no existe una manera f\'acil de hacer un seguimiento de ellos y de hacer que corran autom\'aticamente. Las pruebas que no se ejecutan no ayudan a encontrar bugs!

M\'as a\'un, un m\'etodo de ejemplo no informa al lector sobre el resultado esperado:
puedes correr un ejemplo y ver \,---\,quiz\'as con gran sorpresa\,---\,el resultado, 
pero no sabr\'as si el comportamiento observado es el correcto.

\sunit es valioso porque nos permite escribir pruebas que son chequeadas por s\'i mismas (self-checking):
la prueba misma define cu\'al deber\'ia ser el resultado correcto.
Tambi\'en nos ayuda a organizar pruebas en grupo, para describir el contexto en el cual las pruebas deben correrse,
 y a correrlas en conjunto autom\'aticamente.

En menos de dos minutos puedes escribir pruebas usando \sunit, as\'i que en lugar de escribir peque\~nos fragmentos de c\'odigo en un workspace, te alentamos a usar \sunit y obtener todas las ventajas de las pruebas acumulables y autom\'aticamente ejecutables.

En este cap\'itulo comenzaremos debatiendo por qu\'e hacemos pruebas y qu\'e es lo que hace a un buen desarrollo de pruebas. Luego presentamos una serie de peque\~nos ejemplos mostrando c\'omo usar \sunit.

Por \'ultimo, miraremos la implementaci\'on de \sunit, y de esa forma entender c\'omo \st usa el poder de la \ind{reflexi\'on} en el soporte de sus herramientas.

%=================================================================
\section{Por qu\'e es importante el desarrollo y la ejecuci\'on de las pruebas}
\seclabel{why}

Desafortunadamente, muchos desarrolladores creen que el desarrollo de pruebas es una p\'erdida de tiempo.
Despu\'es de todo, \emph{ellos} no escriben bugs\,---\,s\'olo los \emph{otros} programadores lo hacen.
La mayor\'ia de nosotros ha dicho, en alg\'un momento:
``Yo escribir\'ia pruebas si tuviera m\'as tiempo.''
Si nunca escribieras bugs, y si tu c\'odigo nunca fuera a ser cambiado en el futuro,
entonces las pruebas s\'i ser\'ian una p\'erdida de tiempo.
Sin embargo, esto probablemente significa que tu aplicaci\'on es trivial, o que ya no es usada ni por ti ni por nadie m\'as.  
Piensa en las pruebas como una inversi\'on para el futuro: tener un paquete de pruebas ser\'a bastante \'util ahora,
 pero ser\'a \emph{extremadamente} \'util cuando tu aplicaci\'on, o el entorno en el cual se ejecuta, cambie en el futuro.

Las pruebas juegan muchos roles. Primero, proveen documentaci\'on sobre la funcionalidad que cubren.
M\'as a\'un, la documentaci\'on es activa: ver que las pruebas pasan correctamente te dice que la documentaci\'on est\'a actualizada.

Segundo, las pruebas ayudan a los desarrolladores a confirmar que los cambios que le 
acaban de hacer a un paquete no ha roto nada m\'as en el sistema\,---\,y a encontrar las partes que se rompen cuando la confianza resulta estar fuera de lugar.

Finalmente, escribir las pruebas al mismo tiempo \,---\,o antes\,---\,de programar te obliga a pensar sobre la funcionalidad que quieres dise\~nar, \emph{y c\'omo deber\'ia mostrarse al cliente}, 
y no acerca de c\'omo implementarla.

Escribiendo las pruebas primero\,---\,antes que el c\'odigo\,---\,est\'as obligado a indicar el contexto en el que 
la funcionalidad se ejecutar\'a, la forma en la que va a interactuar con el c\'odigo cliente, y los resultados esperados.  

Tu c\'odigo mejorar\'a: pru\'ebalo.

%The culture of tests has always been present in the \st
%community because after writing a method, we would write a small
%expression to test it.  This practice supports the extremely tight
%incremental development cycle promoted by \st.  However, doing
%so does not bring the maximum benefit from testing because the tests
%are not saved and run automatically.  Moreover it often happens that
%the context of the tests is left unspecified so the reader has to
%interpret the results and assess if they are right or wrong.

No podemos probar todos los aspectos de una aplicaci\'on realista.
Cubrir una aplicaci\'on completa es sencillamente imposible y no ser\'ia el objetivo del desarrollo de pruebas.
Incluso con un buen conjunto de pruebas
algunos bugs a\'un quedar\'an en la aplicaci\'on, donde permanecer\'an latentes, esperando la oportunidad para da\~nar su sistema.
Si encuentras que esto ha ocurrido, ¡aprovech\'alo!
Tan pronto como descubras un bug, escribe una prueba que lo exponga, ejecuta la prueba, y m\'irala fallar.
Ahora puedes comenzar a arreglar el bug: la prueba te dir\'a cu\'ando has terminado.

%=================================================================
%\section{What makes a good test?}
\section{¿Qu\'e hace a una buena prueba?}

Escribir buenas pruebas es una habilidad que puede ser aprendida facilmente con pr\'actica.
Veamos las propiedades que las pruebas deber\'ian tener para obtener el m\'aximo beneficio: 


\begin{enumerate}

%%%%%%% Tests should be repeatable (?)
\item Las pruebas deben poder repetirse. Debes ser capaz de correr una prueba
	las  veces que lo desees, y siempre obtener la misma respuesta.

\item Las pruebas deben correr sin la intervenci\'on humana. Debes ser capaz
	incluso de correrlas durante la noche.

\item Las pruebas deben contar una historia. Cada prueba deber\'ia cubrir un aspecto
	de alguna pieza de c\'odigo. Una prueba deber\'ia actuar como un escenario al que t\'u o alguien m\'as
	pueda leer para entender una parte de la funcionalidad. \label{prop:oneAspect}

\item Las pruebas deber\'ian tener una frecuencia de cambio menor
	a la de la funcionalidad que cubren: no deber\'ias tener que cambiar
	todas tus pruebas cada vez que modificas la aplicaci\'on.  Una forma de lograr
	esto es escribiendo pruebas a base de interfases p\'ublicas de la clase que
	est\'as probando.      
	Es correcto escribir una prueba para un m\'etodo "de ayuda" privado si crees que 
	ese m\'etodo es lo suficientemente complicado para necesitar una prueba, pero debes
	tener en cuenta que dicha prueba puede que sea cambiada, o directamente desechada,
	cuando se te ocurra una mejor implementaci\'on.
\end{enumerate}

Una consecuencia de la propiedad (\ref{prop:oneAspect}) es que 
el n\'umero de pruebas deber\'ia ser algo proporcional al n\'umero de funciones
a ser probadas: cambiando un aspecto del sistema no deber\'ia romper todas las pruebas
excepto por un n\'umero limitado de ellas. Esto es importante porque teniendo 100 pruebas fallando
deber\'ia enviar un mensaje m\'as fuerte que teniendo 10 pruebas fallando.
  
Sin embargo, no siempre es posible alcanzar este caso ideal: 
en particular, si un cambio rompe la inicializaci\'on de un objeto, o el set-up de una prueba,
seguramente causar\'a que las otras pruebas fallen.

\ind{eXtreme Programming} aboga por escribir pruebas antes de escribir el c\'odigo.
Esto parace ir en contra de nuestros instintos como desarrolladores de software. 
Todo lo que podemos decir es: adelante e int\'entalo!
Hemos encontrado que escribir pruebas antes del c\'odigo nos ayuda a saber qu\'e queremos codificar,
nos ayuda a saber cu\'ando hemos terminado, y nos ayuda a visualizar la funcionalidad
de una clase y a dise\~nar su interfaz.

M\'as a\'un, el desarrollo basado en escribir las pruebas primero nos da el \'animo para ir r\'apido, porque no tenemos miedo de estar olvid\'andonos algo importante.


% Now let's write our first test, and show you the benefits of using \SUnit.
%=================================================================

\section{\sunit by example}

Antes de adentrarnos en detalles de \SUnit, mostraremos un ejemplo
paso a paso.

Usaremos un ejemplo que prueba la clase \ct{Set}. Intenta copiar el c\'odigo como sigue.

%---------------------------------------------------------
\subsection{Paso 1: crear la clase de prueba}

\dothis{ Primero debes crear una nueva subclase de \clsind{TestCase} llamada 
\ct{ExampleSetTest}.  Agrega dos variables de instancia de forma tal
que la clase  luzca as\'i: }

%%%%%%c\'odigo fuente a traducir
\begin{classdef}[exampleSetTest]{Ejemplo de una clase de prueba de Set.}
TestCase subclass: #ExampleSetTest
	instanceVariableNames: 'full empty'
	classVariableNames: ''
	poolDictionaries: ''
	category: 'MySetTest'
\end{classdef}


Usaremos la clase \ct{ExampleSetTest} para agrupar todas las pruebas relacionadas con
la clase \ct{Set}.  La misma define el contexto en el cual las pruebas
correr\'an. Aqu\'i el contexto es descripto por las dos variables de instancia \ct{full} y \ct{empty}
que usaremos para representar el set lleno y el set vac\'io.

El nombre de la clase no es cr\'itico, pero por convenci\'on deber\'ia terminar con \ct{Test}.
Si defines una clase llamada \ct{Pattern} y nombras a la correspondiente clase de pruebas \ct{PatternTest},
las dos clases ser\'an indexadas alfab\'eticamente en forma conjunta en el navegador (asumiendo
que ambas se encuentran en la misma categor\'ia).  Es de \emph{suma importancia} que tu clase 
sea una subclase de \ct{TestCase}.

%---------------------------------------------------------
\subsection{Paso 2: inicializar el contexto de prueba}

El m\'etodo \mthind{TestCase}{setUp} define el contexto en el cual las
pruebas correr\'an, es una especie de m\'etodo de inicializaci\'on.
\ct{setUp} es invocado antes de la ejecuci\'on de cada m\'etodo de prueba definido
en la clase de pruebas.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% c\'odigo a traducir
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\index{SUnit!m\'etodo set up}
\seeindex{testing}{SUnit}

\dothis{Define el m\'etodo \ct{setUp} como sigue, para inicializar la variable \ct{empty} que se refiere a un set vacio y a la variable \ct{full} para referirse a un set que contiene elementos. }

\needlines{3}
\begin{method}[setupExampleSetTest]{Setting up a fixture}
ExampleSetTest>>>setUp
	empty := Set new.
	full := Set with: 5 with: 6
\end{method}

\noindent
En la jerga del desarrollo de pruebas, el contexto es llamado el \emph{fixture} para la prueba.

\index{SUnit!fixture}
\seeindex{fixture}{SUnit, fixture}

%---------------------------------------------------------
\subsection{Paso 3: escribir algunos m\'etodos de prueba}

Vamos a crear algunas pruebas definiendo algunos m\'etodos en la clase \ct{ExampleSetTest}.  
Cada m\'etodo representa una prueba: 
el nombre del m\'etodo deber\'ia comenzar con la cadena `\ct{test}' para que \sunit
la tome en su juego de pruebas.

Los m\'etodos de pruebas no toman argumentos.

\dothis{Define los siguientes m\'etodos de prueba.}
La primer prueba, llamada \ct{testIncludes}, prueba al m\'etodo
\ct{includes:} de \ct{Set}.  La prueba dice que enviando el mensaje \ct{includes: 5} a un conjunto
que contiene 5 elementos deber\'ia retornar \ct{verdadero -true}.  Claramente, esta prueba depende de que el
m\'etodo \ct{setUp} ya haya sido corrido.

\begin{method}[testIncludes]{Probando miembro de Set}
ExampleSetTest>>>testIncludes
	self assert: (full includes: 5).
	self assert: (full includes: 6)
\end{method}

La segunda prueba, llamada \ct{testOccurrences}, verifica que el n\'umero de ocurrencias
de ~5 en el set \ct{full} es igual a uno, a\'un cuando agregamos otro elemento ~5 al set.

\needlines{6}
\begin{method}[testOccurrences]{Probando ocurrencias}
ExampleSetTest>>>testOccurrences
	self assert: (empty occurrencesOf: 0) = 0.
	self assert: (full occurrencesOf: 5) = 1.
	full add: 5.
	self assert: (full occurrencesOf: 5) = 1
\end{method}

Finalmente, probamos que el conjunto ya no contiene al elemento 5 despu\'es de que lo hemos removido.

\begin{method}[testRemove]{Probando eliminar}
ExampleSetTest>>>testRemove
	full remove: 5.
	self assert: (full includes: 6).
	self deny: (full includes: 5)
\end{method}

\noindent

Nota el uso del m\'etodo \mthind{TestCase}{deny:} para afirmar que algo no deber\'ia ser 
 verdadero.

\ct{aTest deny: anExpression} es equivalente a \ct{aTest assert: anExpression not}, pero mucho m\'as legible.
%---------------------------------------------------------
\subsection{Paso 4: correr las pruebas}

La forma m\'as f\'acil de correr las pruebas es directamente desde el navegador.
Simplemente \actclick sobre el paquete, nombre de clase o sobre un m\'etodo de prueba individual, 
y selecciona \menu{run the tests(t)}

Los m\'etodos de prueba ser\'an marcados con rojo o verde, dependiendo si pasaron o no, y la clase ser\'a marcada completamente o parcialmente en verde o rojo dependiendo de si todas, algunas o ninguna prueba pas\'o.

\begin{figure}[tbh]
  \begin{center}
	\includegraphics[width=\linewidth]{browser-tests}
	\caption{Running \sunit tests from the browser}
	\figlabel{browser-tests}
  \end{center}
\end{figure}

Tambi\'en puedes elegir varios juegos de pruebas a correr, y obtener un log mas detallado de los resultados
usando \sunit \emphind{Test Runner}, el cual puedes abrir seleccionando \menu{World \go Test Runner}.


El \emph{TestRunner}, mostrado en \figref{test-runner}, esta dise\~nado para hacer m\'as
f\'acil la ejecuci\'on de grupos de pruebas.

El panel de m\'as a la izquierda lista todas las categor\'ias que contienen las clases de pruebas
(\ie subclases de \ct{TestCase}); cuando algunas de estas categor\'ias es seleccionada, las clases de pruebas
que ellas contienen aparecen en el panel de la derecha.
Las clases abstractas se muestran en letra it\'alica, y la jerarqu\'ia de clases de pruebas se muestra con indentaci\'on, as\'i las subclases de \ct{ClassTestCase} estan indentadas m\'as que las subclases de \ct{Testcase}.


\begin{figure}[tbh]
  \begin{center}
	\includegraphics[width=\linewidth]{test-runner}
	\caption{The \pharo \sunit Test Runner}
	\figlabel{test-runner}
  \end{center}
\end{figure}

\dothis{Abre un Test Runner, selecciona la categor\'ia \menu{MyTest}, y haz clic en el bot\'on \button{Run Selected}.}

% ON: With OB, you don't need this.
%You can also run a single test by executing a \menu{print it} on the following code: \ct{ExampleSetTest run: #testRemove}.  
%We usually include an executable comment in our test methods that allows us to run them
%with a \menu{do it} from the browser, as shown in \mthref{ExampleSetTestTestRemoveii}.

%\needlines{6}
%\begin{method}[ExampleSetTestTestRemoveii]{Executable comments in test methods}
%ExampleSetTest>>>testRemove
%	"self run: #testRemove"
%	full remove: 5.
%	self assert: (full includes: 6).
%	self deny: (full includes: 5)
%\end{method}

\dothis{Introduce un error en \ct{ExampleSetTest>>>testRemove} y corre las pruebas nuevamente. Por ejemplo,
cambia \ct{5} por \ct{4}.}

Las pruebas que no pasaron (si es que hay alguna) son listadas a las ventanas de la derecha del \emph{Test Runner};
si quieres debugguear una, para ver por qu\'e fall\'o, s\'olo haz clic sobre el nombre.

%Alternatively, you can execute the following expressions:
%\begin{code}{}
%(ExampleSetTest selector: #testRemove) debug
%\end{code}
%or
%\begin{code}{}
%ExampleSetTest debug: #testRemove
%\end{code}

%---------------------------------------------------------
\subsection{Paso 5: interpretar los resultados}

El m\'etodo \mthind{TestCase}{assert:}\,, el cual est\'a definido en la clase
\ct{TestCase}, espera un argumento de valor booleano, usualmente el valor de 
una expresion evaluada. Cuando el argumento es verdadero (true), la prueba pasa;
cuando el argumento es falso (false), la prueba falla.

En realidad, existen tres posibles retornos de una prueba.
La salida que esperamos es que todas aseveraciones en la prueba sean verdaderas, en cuyo caso la prueba pasa.
En el test runner, cuando todas las pruebas pasan, la barra de arriba se vuelve verde.
Sin embargo, hay dos tipos de cosas que pueden ir mal cuando corres una prueba.

Como es l\'ogico, una de las afirmaciones puede ser falsa, causando que la prueba \emph{falle}. 

No obstante, es posible que algun otro tipo de error ocurra durante la ejecuci\'on de una prueba,
como un error de \emph{message not understood} o un error de \emph{index out of bounds}.

Si un error ocurre, las aserciones en la prueba pueden que no se hayan ejecutado del todo, 
por lo que no podemos decir que la prueba ha fallado; no obstante, algo est\'a claramente mal!

El el \emph{test runner}, las pruebas que fallan causan que la barra superior se vuelva amarilla, 
y son listadas en la ventana del medio sobre la derecha, mientras que
las pruebas erroneas causan que la barra se ponga roja, y son listadas en la ventana inferior de la derecha.

\dothis{Modifica tus pruebas para provocar errores y fallas.}

%=================================================================
\section{El libro de recetas de \SUnit }

Esta secci\'on te dar\'a mas detalles sobre c\'omo usar \SUnit.  Si has usado
otro framework para hacer pruebas como Junit\footnote{\url{http://junit.org}},
gran parte de todo esto te resultar\'a familiar, desde ya que todos estos frameworks tienen
sus raices en \SUnit.
Usualmente usar\'as la GUI de \SUnit para correr las pruebas, pero 
habr\'a situaciones donde puedes no querer usarla.


%---------------------------------------------------------
\subsection{Otras aserciones}
Adem\'as de \ct{assert:} y \ct{deny:}, existen varios otros m\'etodos que pueden
ser usados para hacer aserciones.

Primero, \mthind{Testcase}{assert:description:} y \mthind{TestCase}{deny:description:} toman un segundo
argumento que es un mensaje en una cadena que puede ser usada para describir el motivo de la falla,
si es que no es obvia desde la prueba misma.

Estos m\'etodos estan definidos en~\secref{descriptionStrings}.

Luego, \sunit provee dos m\'etodos adicionales, \mthind{TestCase}{should:raise:} y \mthind{TestCase}{shouldnt:raise:}
para probar la propagaci\'on de una excepci\'on. 

Por ejemplo, podr\'ias usar \ct {(self should: aBlock raise: anException)}
para probar si una excepci\'on en particular es lanzada durante la
ejecuci\'on de \ct{aBlock}. \Mthref{ESTtestIllegal} ilustra el uso de \mbox{\ct{should:raise:}.}


\dothis{Intenta correr esta prueba.}

Nota que el primer argumento de los m\'etodos \ct{should:} y \ct{shouldnt:} es un
\emphind{bloque} que \emph{contiene} la expresi\'on a ser evaluada.

\begin{method}[ESTtestIllegal]{Probando lanzamiento de un error}
ExampleSetTest>>>testIllegal
	self should: [empty at: 5] raise: Error.
	self should: [empty at: 5 put: #zork] raise: Error
\end{method}

\sunit es portable: puede ser usado en todos los dialectos \st.  Para hacer a \sunit portable,
sus desarrolladores no tomaron en consideraci\'on los aspectos que son dependientes
del dialecto. El m\'etodo de clase \cmind{TestResult class}{error} responde a la clase
de error del sistema en una forma que es independiente del dialecto.

Puedes aprovechar esto: si quieres escribir pruebas que funcionar\'an en cualquier dialecto de \st, en vez de \mthref{ESTtestIllegal} podr\'ias escribir:

\needlines{4}
\begin{method}[portabletestillegal]{Portable error handling}
ExampleSetTest>>>testIllegal
	self should: [empty at: 5] raise: TestResult error.
	self should: [empty at: 5 put: #zork] raise: TestResult error
\end{method}

\dothis{Int\'entalo.}

%---------------------------------------------------------
\subsection{Corriendo una sola prueba}
Normalmente, correr\'as las pruebas usando el Test Runner.

Si no quieres abrir el test Runner desde el men\'u \menu{open\,\ldots},
puedes ejecutar \ct{TestRunner open} como un \menu{print it}.

Puedes correr una sola prueba como sigue.

\begin{code}{}
ExampleSetTest run: #testRemove --> 1 run, 1 passed, 0 failed, 0 errors
\end{code}

%---------------------------------------------------------
\subsection{Corriendo todas las pruebas en una clase de pruebas}

Cualquier subclase de \ct{TestCase} responde al mensaje \ct{suite}, el cual
construir\'a un juego de pruebas que contendr\'a todos los
m\'etodos en la clase cuyos nombres empiezen con la cadena ``\ct{test}''.

Para correr las pruebas en el juego, env\'ia el mensaje \ct{run}.

Por ejemplo:

\begin{code}{}
ExampleSetTest suite run --> 5 run, 5 passed, 0 failed, 0 errors
\end{code}

%---------------------------------------------------------
\subsection{¿Debo heredar de TestCase?}

En JUnit{} puedes construir un \clsind{TestSuite} desde cualquier clase arbitraria
que contenga m\'etodos \ct{test*}. En \st puedes hacer lo mismo pero tendr\'as
que crear un juego a mano y tu clase deber\'a implementar todos los m\'etodos esenciales de 
 \ct{TestCase} como por ejemplo, \ct{assert:}.

Recomendamos que no intentes hacer esto. El framework ya est\'a ah\'i: \'usalo.

%=================================================================

\section{El framework SUnit}\label{sec:resource}

\sunit consiste en cuatro clases principales : \clsind{TestCase},
\clsind{TestSuite}, \clsind{TestResult}, y \clsind{TestResource}, como se muestra en \figref{sunit-classes}.
La idea de un \emph{test resource} fue introducida en \sunit 3.1 para representar a un recurso
que es caro de alistar pero que puede ser usado por una serie completa de pruebas.  Un \ct{TestResource}
especifica un m\'etodo \ct{setUp} que es ejecutado s\'olo una vez antes del juego de pruebas;
esto es para distinguir del m\'etodo \ct{TestCase>>>setUp}, el cual es ejecutado antes de cada prueba. 


\begin{figure}[htb]
  \begin{center}
		{\includegraphics[width=0.8\textwidth]{sunit-classes}}
	\caption{Las cuatro clases que representan el coraz\'on de \SUnit}
	\figlabel{sunit-classes}
  \end{center}
\end{figure}


%---------------------------------------------------------
\subsection{TestCase}

\clsindmain{TestCase} es una clase abstracta que esta dise\~nada para ser heredada por alguna otra subclase;
cada una de sus subclases representa un grupo de pruebas que comparten un contexto en com\'un (esto es, un set de pruebas).

Cada prueba se corre creando una nueva instancia de una subclase de \ct{TestCase},
corriendo \mthind{TestCase}{setUp}, corriendo el m\'etodo de prueba en s\'i mismo, y luego
corriendo \mthind{TestCase}{tearDown}.


El contexto esta especificado por las variables de instancia de la subclase y por la 
especializaci\'on del m\'etodo \ct{setUp}, el cual inicializa esas variables
de instancia. Las subclases de \ct{TestCase} pueden tambi\'en sobreescribir el m\'etodo
\ct{tearDown}, el cual es invocado luego de la ejecuci\'on de cada prueba, y puede ser usado para
liberar cualquier objeto creado durante \ct{setUp}.


%---------------------------------------------------------
\subsection{TestSuite}

Las instancias de la clase \clsindmain{TestSuite} contienen una colecci\'on de casos de prueba.
Una instancia de \ct{TestSuite} contiene pruebas, y otra sets de pruebas.

Esto es, un set de pruebas contiene sub-instancias de \ct{TestCase} y \ct{TestSuite}.

Individualmente, tanto los \lct{TestCase}s como los \lct{TestSuite}s entienden el mismo protocolo,
por lo que ambas pueden ser tratadas en la misma forma; por ejemplo, ambas pueden \ct{correrse}.

Esto es de hecho una aplicaci\'on del patr\'on 'composite' en el cual \ct{TestSuite} es el compuesto
y las \ct{TestCase}s son las hojas\,---\,see \textit{Design Patterns} para m\'as informaci\'on sobre este patr\'on \cite{Gamm95a}.

%---------------------------------------------------------
\subsection{TestResult}

La clase \clsindmain{TestResult} representa los resultados de la ejecuci\'on de un \ct{TestSuite}.
Graba los n\'umeros de pruebas pasadas correctamente, el n\'umero de pruebas fallidas y el n\'umero
de errores encontrados.

%---------------------------------------------------------
\subsection{TestResource}
\seclabel{recurso}

Una de las caracter\'isticas mas importantes de un set de pruebas es que 
deber\'an ser independientes unas de otras: la falla de una prueba no deber\'ia causar una avalancha
de fallas en las otras pruebas que dependen de ella, tampoco deber\'ia importar el orden en que se corren las
pruebas.  

Ejecutando \ct{setUp} antes de cada prueba y \ct{tearDown} al final ayuda a reforzar esta independencia.
 
Sin embargo, hay ocasiones en que inicializar el contexto necesario consume demasiado tiempo por lo que no es 
pr\'actico de hacer antes de la ejecuci\'on de cada prueba.

M\'as a\'un, si se sabe que los casos de prueba no afectan los recursos de las pruebas, entonces es un
desperdicio inicializarlas de nuevo por cada prueba; es suficiente inicializarlas una vez por cada juego
de pruebas.
Supongamos, por ejemplo, que un set de pruebas necesita consultar a una base de datos, o hacer
alg\'un tipo de an\'alisis sobre un c\'odigo compilado.
En esos casos, tendr\'ia sentido preparar la base de datos y abrir una conex\'ion, o compilar algo
de c\'odigo, antes de que cualquier prueba comienze a correr.


D\'onde deber\'iamos preservar estos recursos, as\'i pueden ser compartidos por un set de pruebas?
Las variables de instancia de una subclase de \ct{TestCase} en particular no nos sirven, dado que una instancia
existe s\'olo lo que dura una prueba.

Una variable global funcionar\'ia, pero usar demasiadas variables globales ensucia el espacio de nombres,
y el v\'inculo entre lo global y las pruebas que dependen de ello no ser\'a expl\'icito. 

Una mejor soluci\'on es poner los recursos necesarios en un objeto singleton de alguna clase.
La clase \clsindmain{TestResource} existe para que ese tipo de clases de recursos hereden de ella.

Cada subclase de \lct{TestResource}  comprende el mensaje \ct{actual}, al cual responder\'a una instancia singleton de esa subclase.

Los m\'etodos \ct{setUp} y \ct{tearDown} deber\'ian sobreescribirse en la subclase, para tener seguridad de que el
recurso es inicializado y finalizado. 

Una cosa m\'as nos queda pendiente: de alguna forma, \sunit tiene que ser avisado sobre cu\'ales recursos
estan asociados a determinado juego de pruebas.
Un recurso es asociado a una subclcase en particular de \ct{TestCase} sobreescribiendo el m\'etodo de \emph{clase}
\emph{resources}.

%\ab{El conjunto de recursos atribuidos a cada prueba es en realidad el cierre de
%estos recursos bajo The set of resources attributed to each test is actually the closure of these resources under the %resources message, but I think that we don't want to say that!}

Por defecto, los recursos de un \ct{TestSuite} son la uni\'on de los recursos que contienen los 
\ct{TestCase}s. 

Aqu\'i hay un ejemplo.
Definamos una subclase de \ct{TestResource} llamada \ct{MyTestResource} y la asociamos con \ct{MyTestCase}
especializando el m\'etodo de clase \ct{resources} para retornar un vector de las clases de pruebas que vamos 
a usar.

\needlines{8}
\begin{classdef}[mytestresource]{Ejemplo de una subclase de TestResource}
TestResource subclass: #MyTestResource
	instanceVariableNames: ''

MyTestCase class>>>resources
	"associate the resource with this class of test cases"
	^{ MyTestResource }
\end{classdef}

%\needlines{10}
%\begin{classdef}[mytestresource]{An example of a TestResource subclass}
%TestResource subclass: #MyTestResource
%	instanceVariableNames: ''

%MyTestResource>>>setUp
%	"Set up resources here."

%MyTestResource>>>tearDown
%	"Tear down resources here."

%MyTestCase class>>>resources
%	"associate the resource with this class of test cases"
%	^{ MyTestResource }
%\end{classdef}

% \on{Do we really need the empty setUp and tearDown methods here?}

%=================================================================
\section{Cacter\'isticas avanzadas de SUnit}

Adem\'as de \ct{TestResource}, la versi\'on actual de \sunit contiene cadenas de descripci\'on de aserciones,
soporte para logging, y fallas de pruebas reanudables.
%In addition to \ct{TestResource}, the current version of \sunit contains assertion
%description strings, logging support, and resumable test failures.

%---------------------------------------------------------
\subsection{Cadenas de descripci\'on de aserciones}
\seclabel{descriptionStrings}

El protocolo de aserci\'on de \ct{TestCase} incluye un n\'umero de m\'etodos que permiten
al programador proveer descripci\'on sobre lo que se esta comparando en la aserci\'on. La descripci\'on
es un \ct{String}; si la prueba falla, la cadena se mostrar\'a en el test runner. Por supuesto, esta cadena
puede construirse din\'amicamente.

\begin{code}{}
| e |
e := 42.
self assert: e = 23
	description: 'expected 23, got ', e printString
\end{code}

Los  m\'etodos relevantes en \ct{TestCase} son:
\begin{code}{}
#assert:description:
#deny:description:
#should:description:
#shouldnt:description:
\end{code}
\cmindex{TestCase}{assert:description:}
\cmindex{TestCase}{deny:description:}
\cmindex{TestCase}{should:description:}
\cmindex{TestCase}{shouldnt:description:}

%---------------------------------------------------------
\subsection{Soporte para logging}
las cadenas de descripci\'on que arriba se detallaron tambi\'en pueden ser logueadas a un 
\ct{Stream} como por ejemplo el \ct{Transcript}, o un archivo de caracteres.
Puedes elegir hacer reportes con s\'olo sobreescribir \cmind{TestCase}{isLogging} en tu clase de prueba; tambi\'en deber\'as elegir d\'onde reportar sobreescribiendo  \cmind{TestCase}{failureLog} para
responder a un stream apropiado.

%---------------------------------------------------------
\subsection{Continuar despu\'es de una falla}

\sunit tambi\'en nos permite especificar si una prueba deber\'ia continuar luego de una falla, o no. 
Esta es una poderosa caracter\'istica que usa los mecanismos de excepciones ofrecidos por \st.
Para ver en qu\'e puede ser usado, echemos un vistazo a un ejemplo. Considera la siguiente expresi\'on:

\begin{code}{}
aCollection do: [ :each | self assert: each even]
\end{code}

En este caso , tan pronto como la prueba encuentra que primer elemento de la colecci\'on no es \ct{par}, la prueba se detiene.
Sin embargo, usualmente nos gustar\'ia continuar, y ver tambi\'en cu\'antos elementos hay, y qu\'e elementos hay,
no son \ct{pares}, y tal vez reportar esta informaci\'on tambi\'en. Puedes hacer lo siguiente:

\begin{code}{}
aCollection do:
	[:each |
	self
		assert: each even
		description: each printString , ' is not even'
		resumable: true]
\end{code}

Esto imprimir\'a un mensaje en tu stream para logging para cada elemento que falle.
No acumula fallas, \ie, si la aserci\'on falla 10 veces en tu m\'etodo de prueba, ver\'as solamente una sola falla.
Todos los otros m\'etodos de aserci\'on que hemos visto no son reanudables;
\ct{assert: p description: s} es equivalente a \ct{assert: p description: s resumable: false}.
\cmindex{Collection}{do:}
%=================================================================
\section{La implementaci\'on de SUnit}

La implementaci\'on de \sunit constituye un interesante caso de estudio de un framework \st. 
Echemos un vistazo a algunos aspectos clave de la implemntaci\'on siguiendo la ejecuci\'on de una prueba.

%---------------------------------------------------------
\subsection{Corriendo una prueba}

para ejecutar una prueba, evaluamos la expresi\'on
\ct{(aTestClass selector: aSymbol) run.}


\begin{figure}[tbh]
  \begin{center}
		{\includegraphics[width=0.7\textwidth]{sunit-scenario}}
	\caption{Running one test}
	\figlabel{sunit-scenario}
  \end{center}
\end{figure}

El m\'etodo \cmind{TestCase}{run} crea una instancia de 
\clsind{TestResult} que acumular\'a los resultados de las pruebas, luego se env\'ia a s\'i mismo el mensaje  \mthind{TestCase}{run:}.

(Ver \figref{sunit-scenario}.)

\needlines{6}
\begin{method}[tastecaserun]{Running a test case}
TestCase>>>run
	| result |
	result := TestResult new.
	self run: result.
	^result
\end{method}

% Note that in a future release, the class of the \ct{TestResult} to
% be created will be returned by a method so that new
%\ct{TestResult} can be introduced. }

El m\'etodo 
\cmind{TestCase}{run:} env\'ia el mensaje
\mthind{TestResult}{runCase:} al resultado de la prueba:

\begin{method}[testcaserun:]{Passing the test case to the test result}
TestCase>>>run: aResult
	aResult runCase: self
\end{method}

El m\'etodo \ct{TestResult>>>runCase:} env\'ia
el mensaje \mthind{TestCase}{runCase} a una prueba individual, para ejecutar la prueba.

\ct{TestResult>>>runCase} no trata con ninguna excepci\'on que pueda ser
lanzada durante la ejecuci\'on de la prueba, hace correr un\ct{TestCase} enviandole el mensaje
\ct{runCase}, y cuenta los errores, fallas y pasadas.

\begin{method}[testresultruncase]{Catching test case errors and failures}
TestResult>>>runCase: aTestCase
	| testCasePassed |
	testCasePassed := true.
	[[aTestCase runCase] 
			on: self class failure
			do: 
				[:signal | 
				failures add: aTestCase.
				testCasePassed := false.
				signal return: false]]
					on: self class error
					do:
						[:signal |
						errors add: aTestCase.
						testCasePassed := false.
						signal return: false].
	testCasePassed ifTrue: [passed add: aTestCase]
\end{method}

El m\'etodo \ct{TestCase>>>runCase}  env\'ia  los mensajes \mthind{TestCase}{setUp} y \mthind{TestCase}{tearDown}
como se muestra a continuaci\'on. 

\needlines{3}
\begin{method}[testcaseruncase]{Test case template method}
TestCase>>>runCase
	[self setUp.
	self performTest] ensure: [self tearDown]
\end{method}

%---------------------------------------------------------
\subsection{Corriendo un \lct{TestSuite}}

Para correr mas de una prueba, enviamos el mensaje \ct{run} a un \ct{TestSuite} que contenga
las pruebas relevantes.

La \ct{clase TestCase} provee algunas funcionalidades para construir un juego de pruebas desde sus m\'etodos.
La expresi\'on \ct{MyTestCase buildSuiteFromSelectors} retorna un set que contiene todas las 
pruebas definidas en la clase  \ct{MyTestCase}.

El n\'ucleo de este proceso es
\begin{method}[testcasetestselectors]{Contrucci\'on autom\'atica del conjunto de pruebas}
TestCase class>>>testSelectors 
	^self selectors asSortedCollection asOrderedCollection select: [:each | 
		('test*' match: each) and: [each numArgs isZero]]
\end{method}
\cmindex{MyTestCase class}{buildSuiteFromSelectors}

El m\'etodo \cmind{TestSuite}{run} crea una instancia de \ct{TestResult}, verifica que todos los
recursos est\'en disponibles, y luego se env\'ia a s\'i mismo el mensaje \mthind{TestSuite}{run:}, 
el cual corre todas las pruebas en el set. Todos los recursos son liberados luego.

\begin{method}[testsuiterun]{Ejecutando el conjunto de pruebas}
TestSuite>>>run
	| result |
 	result := TestResult new.
	self resources do: [ :res |
		res isAvailable ifFalse: [^res signalInitializationError]].
	[self run: result] ensure: [self resources do: [:each | each reset]].
	^result
\end{method}

\begin{method}[testsuiterun:]{Pasaje del resultado de la prueba al conjunto de pruebas}
TestSuite>>>run: aResult
	self tests do: [:each | 
		self changed: each.
		each run: aResult].
\end{method}


La clase \clsind{TestResource} y sus subclases mantienen un registro de sus instancias
actualmente creadas (uno por clase) que puede ser accedido y creado usando el m\'etodo de clase
\mthind{TestResource class}{current}. Esta instancia se limpia cuando laas pruebas
han terminado de correr y los recursos son restaurados.

La comprobaci\'on de disponibilidad de recursos hace posible que el recurso sea creado de vuelta si es necesario,
como se muestra en el m\'etodo de clase \cmind{TestResource class}{isAvailable}. Durante la
creaci\'on de la instancia de  \ct{TestResource}, es inicializado y el m\'etodo  \mthind{TestResource}{setUp}
es invocado.


%(Note it may happen that your version of \sunit 3.0 does
%not correctly initialize the resource.  A version with this bug
%circulated a lot.  Verify that \ct{TestResource}
%\ct{class>>>new} calls the method \ct{initialize}).

\needlines{4}
\begin{method}[testresourceisavailable]{Disponibilidad del recurso de pruebas}
TestResource class>>>isAvailable
	^self current notNil and: [self current isAvailable]
\end{method}
\begin{method}[testresourcecurrent]{Creaci\'on del recurso de prueba}
TestResource class>>>current
	current isNil ifTrue: [current := self new].
	^current
\end{method}
\begin{method}[restresourceinitialize]{inicializaci\'on de Test resource }
TestResource>>>initialize
	super initialize.
	self setUp
\end{method}
%=================================================================
\section{Algunos consejos sobre testing}

Mientras la mec\'anica de hacer pruebas es f\'acil, escribir buenas pruebas no lo es.
Aqu\'i hay algunos consejos sobre c\'omo dise\~nar pruebas.

\begin{description}
%\item[Self-contained tests.] You do not
%  want to have to change your tests  each time you change your code, so try to write the tests
%  so that they are self-contained.  This can be difficult, but pays off in the
%  long term.  Writing tests in terms of stable interfaces supports
%  self-contained tests.
%  \on{I have no idea what you are trying to tell me.
%  What specifically should I do or not do?
%  Give an example!}

%\item[Do not over-test.] Try to build your tests so that they do not
%  overlap.  It is annoying to have many tests covering the same
%  functionality, because one bug in the code will then break many tests at the same time.
%  This is covered by Black's rule, below.

\index{Feathers, Michael}
\item[Reglas de Feathers para pruebas unitarias.]
  Michael Feathers, un consultor de procesos \'agiles y autor, escribe:\footnote{Ver \url{http://www.artima.com/weblogs/viewpost.jsp?thread=126923}. 9 Septiembre 2005} 
  \begin{quotation}
  \noindent
  {\it
	Una prueba no es una prueba unitaria si:  
  \begin{itemize}
	\item se comunica con la base de datos,
	\item se comunica a trav\'es de la red,
	\item manipula el sistema de archivos,
	\item no puede correr al mismo tiempo que otra de tus pruebas unitarias, o
	\item tienes que hacerle cosas especiales a tu entorno (como por ejemplo editar archivos de configuraci\'on) para correrla.
 \end{itemize}

Las pruebas que hacen estas cosas son malas. Usualmente son valiosas de escribir, y pueden ser escritas
en una unit test harness.
Sin embargo, es importante ser capaz de separarlas de las verdaderas pruebas unitarias para poder
guardar un conjunto de pruebas que puedan correrse r\'apidamente en cualquier momento que hagamos nuestros
cambios.
 }
  \end{quotation}

Nunca llegues a una situaci\'on donde no quieres correr tus pruebas unitarias porque lleva demasiado tiempo.

\item[Pruebas Unitarias \textit{vs.}\ Pruebas de Aceptaci\'on.] Las pruebas unitarias capturan una parte de la funcionalidad, y por tal motivo hacen f\'acil identificar los bugs en esa funcionalidad.
	
Siempre que sea posible, trata de tener pruebas unitarias por cada m\'etodo que puede llegar a fallar, y agr\'upalas por clase. No obstante, para ciertas situaciones, como inicializaciones sumamente recursivas o complicadas, es m\'as f\'acil escribir pruebas que representen un escenario en toda la aplicaci\'on; estos son llamados pruebas de aceptaci\'on o pruebas funcionales. 

Las pruebas que rompen las reglas de  Feathers podr\'ian ser buenas pruebas de aceptaci\'on.
	
Agrupa las pruebas de aceptaci\'on de acuerdo a la funcionalidad que ellas ensayan.
Por ejemplo, si est\'as escribiendo un compilador, podr\'ias escribir pruebas de aceptaci\'on que haga aserciones
sobre el c\'odigo generado para cada posible sentencia del lenguaje fuente. 

Tales pruebas podr\'ian hacer uso de muchas clases, y podr\'ia llevar un largo tiempo correrlas porque
manipulan el sistema de archivos.

Puedes escribirlas usando \sunit, pero no querr\'as correrlas cada vez que hagas un cambio peque\~no, 
as\'i que deber\'iamos separarlas de las verdaderas pruebas unitarias.
 
\item[La regla de Black para el Testing.]

Para cada prueba en el sistema, tienes que ser capaz de identificar alguna propiedad a la cual tu prueba incrementa tu confianza.

Es obvio que habr\'an propiedades no importantes que no estas comprobando.
Esta regla plantea el hecho menos obvio de que no deber\'ia haber pruebas que no agreguen valor al sistema incrementando tu confianza en alguna propiedad del mismo.

Por ejemplo, muchas pruebas del mismo atributo no hacen bien.
De hecho, dan\~nan en dos formas.

Primero, hacen m\'as dificil inferir el comportamiento de la clase leyendo solamente la prueba.
Segundo, como un bug en el c\'odigo podr\'ia romper muchas pruebas, hace m\'as dificil estimar cu\'antos bugs
a\'un restan en el c\'odigo.

Entonces, ten un atributo en mente cuando escribes una prueba.

\end{description}

%\section{Extending \SUnit}
%\seclabel{extending}

%In this section we will explain how to extend \sunit so that it uses
%a \ct{setUp} and \ct{tearDown} that are shared by all of the
%tests in a \ct{TestCase} subclass.  We will define a new sublass
%of \ct{TestCase} called \ct{SharingSetUpTestCase}, and a
%subclass of \ct{SharingSetUpTestCase} called \ct{SharedOne}.
%We will also need to define a new subclass of \ct{TestSuite}
%called \ct{SharedSetUpTestSuite}, and we will make some minor
%adjustments to \ct{TestCase}.

%Our tests will be in \ct{SharedOne}.  When we execute
%\begin{script}
%Transcript clear.
%SharedOne suite run
%\end{script}
%we will obtain the following trace.
%\begin{code}{}
%SharedOne>>>setUp
%SharedOne class>>>sharedSetUp
%SharedOne>>>testOne
%SharedOne>>>tearDown
%SharedOne>>>setUp
%SharedOne>>>testTwo
%SharedOne>>>tearDown
%SharedOne class>>>sharedTearDown
%2 run, 2 passed, 0 failed, 0 errors
%\end{code}
%You can see that the shared code is executed just once for both
%tests.

%\subsection{\ct{SharedSetUpTestCase}}

%The extension of the \sunit framework is based on the introduction
%of two classes: \ct{SharedSetUpTestCase} and
%\ct{SharedSetUpTestSuite}.  The basic idea is to use a flag that
%is flushed (cleared) after a certain number of tests have been run.
%The class \ct{SharedSetUpTestCase} defines one instance variable
%that indicates whether each test is run individually or in the context
%of a shared \ct{setUp} and \ct{tearDown}.  There are also two
%class instance variables.  One indicates the number of tests for which
%the shared \ct{setUp} should be in effect, and the other indicates
%whether the shared \ct{setUp} is in effect.
%\begin{method}[xxx]{xxx}
%SharedSetUpTestCase
%	superclass: TestCase
%	instanceVariableNames: 'runIndividually '
%	classInstanceVariableNames: 'numberOfTestsToTearDown
%								 sharedSetUp '
%\end{method}
%\ct{suiteClass} is used by \ct{TestCase} to determine the
%suite that is running.
%\begin{method}[xxx]{xxx}
%SharedSetUpTestCase class>>>suiteClass
%	^SharedSetUpTestSuite
%\end{method}
%\begin{method}[xxx]{xxx}
%SharedSetUpTestCase class>>>sharedSetUp
%	"A subclass should only override this hook to define
%	 a sharedSetUp"
%\end{method}
%\begin{method}[xxx]{xxx}
%SharedSetUpTestCase class>>>sharedTearDown
%	"Here we specify the teardown of the shared setup"
%\end{method}
%\begin{method}[xxx]{xxx}
%SharedSetUpTestCase class>>>flushSharedSetUp
%	sharedSetUp := nil
%\end{method}
%The \ct{SharedSetUpTestCase} class is initialized with the number
%of tests for which the shared \ct{setUp} should be in effect.
%\begin{method}[xxx]{xxx}
%SharedSetUpTestCase class>>>armTestsToTearDown: aNumber
%	self flushSharedSetUp.
%	numberOfTestsToTearDown := aNumber.
%\end{method}
%Every time a test is run, the method \ct{anothertestHasBeenRun} is
%invoked.  Once the specified number of tests is reached the
%\ct{sharedSetUp} is flushed and the \ct{sharedTearDown} is
%executed.
%\begin{method}[xxx]{xxx}
%SharedSetUpTestCase class>>>anotherTestHasBeenRun
%	"Everytimes a test is run this method is called,
%	 once all the tests of the suite
%	 are run the shared setup is reset"
%	numberOfTestsToTearDown := numberOfTestsToTearDown - 1.
%	numberOfTestsToTearDown isZero
%		ifTrue:
%			[self flushSharedSetUp.
%			self sharedTearDown]
%\end{method}
%When a test is run its \ct{setUp} is executed and it then it calls
%the class method \ct{privateSharedSetUp}.  This method will only
%invoke the \ct{sharedSetUp} if the \ct{sharedSetUp} test
%indicates that it hasn't been done yet.
%\begin{method}[xxx]{xxx}
%SharedSetUpTestCase class>>>privateSharedSetUp
%	sharedSetUp isNil
%		ifTrue:
%			[sharedSetUp := 1.
%			self sharedSetUp]
%\end{method}
%\begin{method}[xxx]{xxx}
%SharedSetUpTestCase>>>setUp
%	self class privateSharedSetUp
%\end{method}
%\begin{method}[xxx]{xxx}
%SharedSetUpTestCase>>>tearDown
%	self class anotherTestHasBeenRun
%\end{method}
%When a test case is created we assume that it will be run once.  We
%can change this later by invoking the method
%\ct{executedFromASuite}.
%\begin{method}[xxx]{xxx}
%SharedSetUpTestCase>>>setTestSelector: aSymbol
%	"Must do it this way because there is no initialize"

%	runIndividually := true.
%	super setTestSelector: aSymbol
%\end{method}
%\begin{method}[xxx]{xxx}
%SharedSetUpTestCase>>>executedFromASuite
%	runIndividually := false
%\end{method}
%The methods responsible for test execution are then specialized as
%follows.
%\begin{method}[xxx]{xxx}
%runIndividually
%	^runIndividually
%\end{method}
%\begin{method}[xxx]{xxx}
%SharedSetUpTestCase>>>armTearDownCounter
%	self runIndividually
%		ifTrue: [self class armTestsToTearDown: 1]
%\end{method}
%\begin{method}[xxx]{xxx}
%SharedSetUpTestCase>>>runCaseAsFailure
%	self armTearDownCounter.
%	super runCaseAsFailure
%\end{method}
%\begin{method}[xxx]{xxx}
%SharedSetUpTestCase>>>runCase
%	self armTearDownCounter.
%	super runCase
%\end{method}

%\subsection{\ct{SharedOne}}

%\ct{SharedOne} is a new class which inherits from
%\ct{SharingSetUpTestCase} as follows.  We define two simple tests
%\ct{testOne} and \ct{testTwo}.
%\begin{method}[xxx]{xxx}
%SharedOne
%	superclass: SharingSetUpTestCase
%\end{method}
%\begin{method}[xxx]{xxx}
%SharedOne>>>testOne
%	Transcript
%		show: 'SharedOne>>>testOne';
%		cr
%\end{method}
%\begin{method}[xxx]{xxx}
%SharedOne>>>testTwo
%	Transcript
%		show: 'SharedOne>>>testTwo';
%		cr
%\end{method}
%Then we define the methods \ct{setUp} and \ct{tearDown} that
%will be executed before and after the execution of the tests exactly
%in the same way as with non sharing tests.  Note however, the fact
%that with the solution we will present we have to explicitly invoke
%the \ct{setUp} method and \ct{tearDown} of the superclass.
%\begin{method}[xxx]{xxx}
%SharedOne>>>setUp
%	Transcript
%		show: 'SharedOne>>>setUp';
%		cr.
%	super setUp
%\end{method}
%\begin{method}[xxx]{xxx}
%SharedOne>>>tearDown
%	Transcript
%		show: 'SharedOne>>>tearDown';
%		cr.
%	super tearDown
%\end{method}
%Finally, we define the methods \ct{sharedSetUp} and
%\ct{sharedTearDown} that will be only executed once for the two
%tests.  Note that this solution assumes that the tests are not
%destructive to the shared fixture, but just query it.
%\begin{method}[xxx]{xxx}
%SharedOne class>>>sharedSetUp
%	Transcript
%		show: 'SharedOne class>>>sharedSetUp';
%		cr
%	"My set up here."
%\end{method}
%\begin{method}[xxx]{xxx}
%SharedOne class>>>sharedTearDown
%	Transcript
%		show: 'SharedOne class>>>sharedTearDown';
%		cr
%	"My tear down here."
%\end{method}

%\subsection{\ct{SharedSetUpTestSuite}}

%The \ct{SharedSetUpTestSuite} defines just one instance variable
%\ct{testCaseClass} and redefines the two methods necessary to run
%the test suite \ct{run:} and \ct{run}.
%\ct{checkAndArmSharedSetUp} initializes the number of tests to run
%before the shared \ct{tearDown} is executed.
%\begin{method}[xxx]{xxx}
%SharedSetUpTestSuite
%	superclass: TestSuite
%	instanceVariableNames: 'testCaseClass'
%\end{method}
%\begin{method}[xxx]{xxx}
%SharedSetUpTestSuite>>>checkAndArmSharedSetUp
%	self tests isEmpty
%		ifFalse: [self tests first class
%				 armTestsToTearDown: self tests size]
%\end{method}
%\begin{method}[xxx]{xxx}
%SharedSetUpTestSuite>>>run: aResult
%	self checkAndArmSharedSetUp.
%	^super run: aResult
%\end{method}
%\begin{method}[xxx]{xxx}
%SharedSetUpTestSuite>>>run
%	self checkAndArmSharedSetUp.
%	^super run
%\end{method}
%Finally the method \ct{addTest:} is specialized so that it marks
%all its tests with the fact that they are executed in a
%\ct{TestSuite} and checks whether all its tests are from the same
%class to avoid inconsistency.
%\begin{method}[xxx]{xxx}
%SharedSetUpTestSuite>>>addTest: aTest
%	"Sharing a setup only works if the test case
%	composing the test suite are from
%	the same class so we test it"

%	aTest executedFromASuite.
%	testCaseClass isNil
%		ifTrue: [testCaseClass := aTest class.
%				super addTest: aTest ]
%		ifFalse: [aTest class == testCaseClass
%				  ifFalse: [self error:
%						   'you cannot have test case of
%							different classes in
%							a SharingSetUpTestSuite'.]
%				  ifTrue: [super addTest: aTest]]
%\end{method}

%\subsection{Changes to \ct{TestCase}}

%In order for the above changes to work, you must make
%\ct{TestCase} aware of your new test suite.
%\begin{method}[xxx]{xxx}
%TestCase class>>>buildSuite
%	| suite |
%	^self isAbstract
%		ifTrue:
%			[suite := self suiteClass new.
%			suite name: self name asString.
%			self allSubclasses
%				do: [:each |
%					each isAbstract
%						ifFalse: [suite addTest:
%						  each buildSuiteFromSelectors]].
%			suite]
%		ifFalse: [self buildSuiteFromSelectors]
%\end{method}
%\begin{method}[xxx]{xxx}
%TestCase class>>>buildSuiteFromMethods: testMethods
%	^testMethods
%		inject: ((self suiteClass new)
%				name: self name asString;
%				yourself)
%		into:
%			[:suite :selector |
%			suite
%				addTest: (self selector: selector);
%				yourself]
%\end{method}
%If you have made all the changes correctly, you should be able to run
%your tests and see the results shown in section~\ref{sec:extending}.
%
%\section{Exercise}

%The previous section was designed to give you some insight into the
%workings of \SUnit.  You can obtain the same effect by using \SUnit's
%resources.

%Create new classes \ct{MyTestResource} and \ct{MyTestCase}
%which are subclasses of \ct{TestResource} and \ct{TestCase}
%respectively.  Add the appropriate methods so that the following
%messages are written to the \ct{Transcript} when you run your
%tests.

%\begin{method}[xxx]{xxx}
%MyTestResource>>>setUp has run.
%MyTestCase>>>setUp has run.
%MyTestCase>>>testOne has run.
%MyTestCase>>>tearDown has run.
%MyTestCase>>>setUp has run.
%MyTestCase>>>testTwo has run.
%MyTestCase>>>tearDown has run.
%MyTestResource>>>tearDown has run.
%\end{method}

%% You need to write the following six methods.

%% MyTestCase>>>setUp
%%	 Transcript
%%		 show: 'MyTestCase>>>setUp has run.';
%%		 cr

%% MyTestCase>>>tearDown
%%	 Transcript
%%		 show: 'MyTestCase>>>tearDown has run.';
%%		 cr

%% MyTestCase>>>testOne
%%	 Transcript
%%		 show: 'MyTestCase>>>testOne has run.';
%%		 cr

%% MyTestCase>>>testTwo
%%	 Transcript
%%		 show: 'MyTestCase>>>testTwo has run.';
%%		 cr

%% MyTestCase class>>>resources
%%	 ^Array with: MyTestResource

%% MyTestResource>>>setUp
%%	 Transcript
%%		 show: 'MyTestResource>>>setUp has run';
%%		 cr

%% MyTestResource>>>tearDown
%%	 Transcript
%%		 show: 'MyTestResource>>>tearDown has run.';
%%		 cr
%=================================================================
\section{Resumen del cap\'itulo}

En este cap\'itulo se ha explicado por qu\'e las pruebas son una importante inversi\'on
en el futuro de tu c\'odigo.

Explicamos en un modo paso a paso c\'omo definimos unas cuantas pruebas para la clase \ct{Set}.
Luego hicimos un recorrido por el n\'ucleo del framework \sunit presentando
las clases  \ct{TestCase}, \ct{TestResult}, \ct{TestSuite} y \lct{TestResources}. Por \'ultimo, profundizamos en \sunit siguiendo la ejecuci\'on de una prueba y de un conjunto de pruebas.

\begin{itemize}
  \item Para maximixar su potencia, las pruebas unitarias deber\'ian ser r\'apidas, repetibles, independientes de cualquier interacci\'on humana y cubrir una \'unica funcionalidad.

  \item Las pruebas para una clase llamada \ct{MyClass} pertencen a una clase clasificada como \ct{MyClassTest}, la cual deber\'ia ser presentada como una subclase de \lct{TestCase}.
  \item Inicializar tus datos de prueba en un m\'etodo \ct{setUp}.
  \item Cada m\'etodo de prueba deber\'ia empezar con la palabra ``test''.
  \item Usa los m\'etodos de \ct{TestCase} :  \ct{assert:}, \ct{deny:} y otros para hacer aserciones.
  \item Corre las pruebas usando la herramienta test runner de SUnit (en la barra de herramientas).
\end{itemize}

%=============================================================
\ifx\wholebook\relax\else
   \bibliographystyle{jurabib}
   \nobibliography{scg}
   \end{document}
\fi
%=============================================================
%%% Local Variables:
%%% coding: utf-8
%%% mode: latex
%%% TeX-master: t
%%% TeX-PDF-mode: t
%%% ispell-local-dictionary: "english"
%%% End:
